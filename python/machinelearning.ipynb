{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W241 Final Project - Craigslist Ads: Machine Learning Approach\n",
    "\n",
    "Trying to find a connection between treatment and outcomes using machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/MIDS/W241/final project/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make dummy variables out of our categorical variables\n",
    "for col in ['author', 'city', 'day']:\n",
    "    df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    df = df.drop(col, 1)\n",
    "    \n",
    "# Convert missing values (avgoffer) to 0\n",
    "df = df.convert_objects(convert_numeric=True)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split/Score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score function based on a random split into train/test data\n",
    "def score(X, Y, clf, test_size=0.33, random_state=42):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    return clf.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Thinking of this as a classification problem, we can't use a continous variable as a categorical one representing the class. So we can't do this...\n",
    "\n",
    "```python\n",
    "X = np.array(df['treatment'])\n",
    "Y = np.array(df['rtotal'])\n",
    "```\n",
    "\n",
    "But we can do the reverse, i.e. try to predict the treatment status from the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454545454545\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df['rtotal']).reshape(len(df), 1)\n",
    "Y = np.array(df['treatment'])\n",
    "\n",
    "# Now we'll try to train a model and see how the predictions go. Let's start with logistic regression.\n",
    "print score(X, Y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great. In fact, not as good as random. But one problem here is that the matched pairs design is not being taken into account. The difference in offer counts is taken in absolute terms, not relative to the pair splits. To address this, create a new column containing the difference between the number of offers and the mean for that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(df.groupby('pairid')['rtotal'].mean(), on='pairid', rsuffix='_pairmean')\n",
    "df['rtotal_diff'] = df.rtotal - df.rtotal_pairmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using that as our feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606060606061\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df['rtotal_diff']).reshape(len(df), 1)\n",
    "print score(X, Y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better. Let's try combining that with all our factor covariates to see if it helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.484848484848\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    'rtotal_diff', \n",
    "    'city_1', 'city_2', 'city_3', 'city_4', 'city_5',\n",
    "    'author_Daniel', 'author_Jonathan', 'author_Kyle', 'author_Raja', 'author_Umber',\n",
    "    'day_1', 'day_2', 'day_3', 'day_4',\n",
    "]\n",
    "X = np.array([df[col] for col in cols]).T\n",
    "\n",
    "print score(X, Y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. Let's try the same approach with the other outcome measurements: using the difference between their values and the mean for the pair as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(df.groupby('pairid')['avgoffer'].mean(), on='pairid', rsuffix='_pairmean')\n",
    "df['avgoffer_diff'] = df.avgoffer - df.avgoffer_pairmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515151515152\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df['avgoffer_diff']).reshape(len(df), 1)\n",
    "print score(X, Y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636363636364\n"
     ]
    }
   ],
   "source": [
    "X = np.array([df[col] for col in ['rtotal_diff', 'avgoffer_diff']]).T\n",
    "print score(X, Y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.join(df.groupby('pairid')['roffer'].mean(), on='pairid', rsuffix='_pairmean')\n",
    "df['roffer_diff'] = df.roffer - df.roffer_pairmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "X = np.array([df[col] for col in ['rtotal_diff', 'avgoffer_diff', 'roffer_diff']]).T\n",
    "print score(X, Y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we've been able to correctly predict the treatment status on 2/3 of the ads based on the outcomes. Could be worse.\n",
    "\n",
    "Let's try it with a couple other classifier types just for fun..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575757575758\n"
     ]
    }
   ],
   "source": [
    "print score(X, Y, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454545454545\n"
     ]
    }
   ],
   "source": [
    "print score(X, Y, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-aways\n",
    "\n",
    "This approach weakly suggests a relationship between the outcomes and treatment. We could try tuning the regression and/or some different algorithms, but this is a very small dataset for machine learning, so the likelihood of overfitting is high and the validity is questionable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
